# -*- coding: utf-8 -*-
"""FP2-Data-Pipeline-AWS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CXSzPD213lfvWdUmpJF4y5qBbcVDLJeM

**Project 1:**

Background:

Stock prices fluctuate rapidly multiple times every second. Investing in stocks using a hunch may
wipe off millions of dollars but taking an informed decision will always yield good results. Stocks
across the globe are fluctuating a lot due to the global volatility, post covid. Having an idea on which
way the stock numbers are going to swing gives a rough idea for investors.

**Objective: Stock Forecasting**

Extract stock data of any one company from https://finance.yahoo.com/. Per hour per IP address
one can pass 2000 requests, on an average. (note: there might be frequent changes to the request
count by Yahoo Finance).

Build a pipeline to extract the data on ongoing basis and forecast stock
(long term and short term). Team can decide the definition of long term and short term. Adjusted
closing price must be forecasted.
Note:
Pandas_datareader can be explored but it is not mandatory to use this.

# New Section
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Setup working directory
# %cd /content/drive/My Drive/Colab Notebooks/FP2

# Commented out IPython magic to ensure Python compatibility.
# # Create requirements file
# %%writefile data_pipeline_requirements.txt
# 
# yfinance>=0.1.55
# numpy>=1.12.0
# pandas>=0.19
# yahoo_fin
# psycopg2

!pip install -r data_pipeline_requirements.txt

# Import necessary libraries

import numpy as np
import pandas as pd
from yahoo_fin.stock_info import get_data
import datetime
from datetime import datetime
# import yfinance as yf
import psycopg2
from sqlalchemy import create_engine

# Setup database connection details
db_credentials = {
    'user': 'goutham',
    'password': 'SharpMinded',
    'host': 'my-term5-db-instance.cdcogaqzqvwg.us-east-1.rds.amazonaws.com',
    'database': 'term5_default_database'
}

# Connection using psycopg2
conn = psycopg2.connect(**db_credentials)

# Define the stock ticker and date range
Stock_ticker = "AAPL"
start_date = "2008-04-01"
end_date = datetime.now().strftime('%Y-%m-%d')  # Formats the current date as a string

# Daily data
daily_data=get_data(Stock_ticker, start_date=start_date, end_date=end_date, index_as_date = False, interval="1d")
daily_data = pd.DataFrame(daily_data)

# Monthly data
monthly_data=get_data(Stock_ticker, start_date=start_date, end_date=end_date, index_as_date = False, interval="1mo")
monthly_data = pd.DataFrame(monthly_data)

print("daily rows imported: ", len(daily_data))
print("monthly rows imported: ", len(monthly_data))
daily_data.tail()

# Drop NA

daily_data.dropna(how='any',inplace=True)
print("daily rows after dropping na: ", len(daily_data))
monthly_data.dropna(how='any',inplace=True)
print("monthly rows after dropping na: ", len(monthly_data))

# Using pandas to_sql to insert data into the PostgreSQL table
engine = create_engine(f'postgresql+psycopg2://{db_credentials["user"]}:{db_credentials["password"]}@{db_credentials["host"]}/{db_credentials["database"]}')

daily_table_name = 'daily_data_aapl'
daily_data.to_sql(daily_table_name, engine, if_exists='replace', index=False)

monthly_table_name = 'monthly_data_aapl'
monthly_data.to_sql(monthly_table_name, engine, if_exists='replace', index=False)

#Check db to confirm table writes

daily_table_name = 'daily_data_aapl'
monthly_table_name = 'monthly_data_aapl'

# Query to select all rows from the table
daily_select_query = f"SELECT * FROM {daily_table_name}"
monthly_select_query = f"SELECT * FROM {daily_table_name}"

# Using pandas read_sql to read data into a DataFrame
daily_df = pd.read_sql(daily_select_query, conn)
monthly_df = pd.read_sql(monthly_select_query, conn)

# Closing the connection
conn.close()

print("daily rows after dropping na: ", len(daily_data))
print("monthly rows after dropping na: ", len(monthly_data))

